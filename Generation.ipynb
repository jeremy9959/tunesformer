{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from utils import *\n",
    "import re\n",
    "from config import *\n",
    "from transformers import GPT2Config\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchilizer = Patchilizer()\n",
    "patch_config = GPT2Config(\n",
    "        num_hidden_layers=PATCH_NUM_LAYERS,\n",
    "        max_length=PATCH_LENGTH,\n",
    "        max_position_embeddings=PATCH_LENGTH,\n",
    "        vocab_size=1,\n",
    "    )\n",
    "char_config = GPT2Config(\n",
    "        num_hidden_layers=CHAR_NUM_LAYERS,\n",
    "        max_length=PATCH_SIZE,\n",
    "        max_position_embeddings=PATCH_SIZE,\n",
    "        vocab_size=128,\n",
    "    )\n",
    "model = TunesFormer(patch_config, char_config, share_weights=SHARE_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'weights/weights.pth'\n",
    "checkpoint = torch.load(weights_file)\n",
    "fixed_weights = {\n",
    "    k: v\n",
    "    for k, v in checkpoint[\"model\"].items()\n",
    "    if not re.search(\"\\.attn.bias|\\.attn.masked_bias\", k)\n",
    "}\n",
    "model.load_state_dict(fixed_weights)\n",
    "model = model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:2\n",
      "B:9\n",
      "E:4\n",
      "B:9\n",
      "L:1/8\n",
      "M:4/4\n",
      "K:D\n",
      " de |\"D\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"prompt.txt\", \"r\") as f:\n",
    "    prompt = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "S:2\n",
    "E:4\n",
    "B:9\n",
    "L:1/8\n",
    "M:4/4\n",
    "K:D\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunes = \"\" \n",
    "num_tunes = 1 \n",
    "max_patch = 128\n",
    "top_p = .8 \n",
    "top_k = 10 \n",
    "temperature = 1.2\n",
    "seed = None\n",
    "show_control_code = True \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nS:2\\nE:4\\nB:9\\nL:1/8\\nM:4/4\\nK:D\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_patches = torch.tensor([patchilizer.encode(prompt,add_special_patches=True)[:-1]],device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 32])\n",
      "->tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 2], device='cuda:0')\n",
      "S:2\n",
      "->tensor([ 1, 83, 58, 50, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "E:4\n",
      "->tensor([ 1, 69, 58, 52, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "B:9\n",
      "->tensor([ 1, 66, 58, 57, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "L:1/8\n",
      "->tensor([ 1, 76, 58, 49, 47, 56, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "M:4/4\n",
      "->tensor([ 1, 77, 58, 52, 47, 52, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "K:D\n",
      "->tensor([ 1, 75, 58, 68, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(input_patches.shape)\n",
    "for x in input_patches[0]:\n",
    "    print(f\"{patchilizer.patch2bar(x)}->{x}\")\n",
    "# each input_patch[0,i] corresponds to a line of the prompt (encoded), with bos and eos appended\n",
    "# the first patch input_patches[0,0] is the special indicator for the start of the tune\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:2\n",
      "E:4\n",
      "B:9\n",
      "L:1/8\n",
      "M:4/4\n",
      "K:D\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefix = patchilizer.decode(input_patches[0])\n",
    "print(prefix,\"\\n\")\n",
    "remaining_tokens = prompt[len(prefix):]\n",
    "print(remaining_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.tensor([patchilizer.bos_token_id]+[ord(c) for c in remaining_tokens],device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 10], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dB |\n",
      " F>G |\n",
      " dA (3AAA A2 AB |\n",
      " de |\n",
      " dB |\n",
      " AB/c/ |\n",
      " d3 c dAFA |\n",
      " (A F2) (A FE)DE |\n",
      " AG |\n",
      " F>E |\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    p, s = model.generate(\n",
    "        input_patches,\n",
    "        tokens,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        temperature=temperature,\n",
    "        seed=seed,\n",
    "    )\n",
    "    print(patchilizer.patch2bar(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 32])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## compute bar embedding \n",
    "# start with input patches 1 x L x 32 with special patches at front and back\n",
    "# input_patches = torch.tensor([patchilizer.encode(prompt,add_special_patches=True)[:-1]],device=device)\n",
    "# omit the last special patch \n",
    "input_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 32])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape to (len(patches, -1, 32))\n",
    "patches = input_patches.reshape(len(input_patches),-1, PATCH_SIZE)\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 32])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.patch_level_decoder(patches)[\"last_hidden_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([patchilizer.encode(\"K:D\\n\",add_special_patches=True)[:-1]])\n",
    "embedding = model.patch_level_decoder(input)[\"last_hidden_state\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0125,  0.0160,  0.1532,  ...,  0.0690,  0.1152,  0.0471],\n",
       "         [ 0.2039, -0.7142,  1.0180,  ...,  1.7600,  0.2193, -1.0058]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"abcs/whiskey-before-breakfast.abc\") as f:\n",
    "    whiskey = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nX:1\\nL:1/8\\nM:4/4\\nK:D\\n|: \"D\"DE FG A2 AA | AB AG FE DF | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF EC B,A, |\\n\"D\"DE FG A2 AA | AB AG FE DF | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF \"D\"D2 A2 ::\\n\"D\"A2 d2 d2 dd | f2 d2 B2 A2 | \"Em (A)\"e2 ef e2 ef | \"A7\" gf ed cB Ac |\\n\"D\"d2 fd \"A\"c2 ec | \"G\"Bc dB \"D\"AF ED | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF \"D\"D2-D2 :|\\n\\n'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiskey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiskey_patches = torch.tensor([patchilizer.encode(whiskey,add_special_patches=True)[:-1]],device=device)\n",
    "whiskey_embedding = model.patch_level_decoder(whiskey_patches)[\"last_hidden_state\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 2], device='cuda:0')\n",
      "X:1\n",
      "->tensor([ 1, 88, 58, 49, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "L:1/8\n",
      "->tensor([ 1, 76, 58, 49, 47, 56, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "M:4/4\n",
      "->tensor([ 1, 77, 58, 52, 47, 52, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "K:D\n",
      "->tensor([ 1, 75, 58, 68, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "|: \"D\"DE FG A2 AA |->tensor([  1, 124,  58,  32,  34,  68,  34,  68,  69,  32,  70,  71,  32,  65,\n",
      "         50,  32,  65,  65,  32, 124,   2,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " AB AG FE DF |->tensor([  1,  32,  65,  66,  32,  65,  71,  32,  70,  69,  32,  68,  70,  32,\n",
      "        124,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"G\"G2 BG \"D\"F2 AF |->tensor([  1,  32,  34,  71,  34,  71,  50,  32,  66,  71,  32,  34,  68,  34,\n",
      "         70,  50,  32,  65,  70,  32, 124,   2,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"A\"ED EF EC B,A, |->tensor([  1,  32,  34,  65,  34,  69,  68,  32,  69,  70,  32,  69,  67,  32,\n",
      "         66,  44,  65,  44,  32, 124,   2,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      "\n",
      "\"D\"DE FG A2 AA |->tensor([  1,  10,  34,  68,  34,  68,  69,  32,  70,  71,  32,  65,  50,  32,\n",
      "         65,  65,  32, 124,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " AB AG FE DF |->tensor([  1,  32,  65,  66,  32,  65,  71,  32,  70,  69,  32,  68,  70,  32,\n",
      "        124,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"G\"G2 BG \"D\"F2 AF |->tensor([  1,  32,  34,  71,  34,  71,  50,  32,  66,  71,  32,  34,  68,  34,\n",
      "         70,  50,  32,  65,  70,  32, 124,   2,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"A\"ED EF \"D\"D2 A2 ::->tensor([ 1, 32, 34, 65, 34, 69, 68, 32, 69, 70, 32, 34, 68, 34, 68, 50, 32, 65,\n",
      "        50, 32, 58, 58,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "\n",
      "\"D\"A2 d2 d2 dd |->tensor([  1,  10,  34,  68,  34,  65,  50,  32, 100,  50,  32, 100,  50,  32,\n",
      "        100, 100,  32, 124,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " f2 d2 B2 A2 |->tensor([  1,  32, 102,  50,  32, 100,  50,  32,  66,  50,  32,  65,  50,  32,\n",
      "        124,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"Em (A)\"e2 ef e2 ef |->tensor([  1,  32,  34,  69, 109,  32,  40,  65,  41,  34, 101,  50,  32, 101,\n",
      "        102,  32, 101,  50,  32, 101, 102,  32, 124,   2,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"A7\" gf ed cB Ac |->tensor([  1,  32,  34,  65,  55,  34,  32, 103, 102,  32, 101, 100,  32,  99,\n",
      "         66,  32,  65,  99,  32, 124,   2,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      "\n",
      "\"D\"d2 fd \"A\"c2 ec |->tensor([  1,  10,  34,  68,  34, 100,  50,  32, 102, 100,  32,  34,  65,  34,\n",
      "         99,  50,  32, 101,  99,  32, 124,   2,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"G\"Bc dB \"D\"AF ED |->tensor([  1,  32,  34,  71,  34,  66,  99,  32, 100,  66,  32,  34,  68,  34,\n",
      "         65,  70,  32,  69,  68,  32, 124,   2,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"G\"G2 BG \"D\"F2 AF |->tensor([  1,  32,  34,  71,  34,  71,  50,  32,  66,  71,  32,  34,  68,  34,\n",
      "         70,  50,  32,  65,  70,  32, 124,   2,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n",
      " \"A\"ED EF \"D\"D2-D2 :|->tensor([  1,  32,  34,  65,  34,  69,  68,  32,  69,  70,  32,  34,  68,  34,\n",
      "         68,  50,  45,  68,  50,  32,  58, 124,   2,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for x in whiskey_patches[0]:\n",
    "    print(f\"{patchilizer.patch2bar(x)}->{x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.tensor([patchilizer.bos_token_id],device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_token = model.char_level_decoder.generate(whiskey_embedding[0,1],tokens).argmax()\n",
    "tokens = torch.cat([tokens,new_token.unsqueeze(0)],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nX:1\\nL:1/8\\nM:4/4\\nK:D\\n|: \"D\"DE FG A2 AA | AB AG FE DF | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF EC B,A, |\\n\"D\"DE FG A2 AA | AB AG FE DF | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF \"D\"D2 A2 ::\\n\"D\"A2 d2 d2 dd | f2 d2 B2 A2 | \"Em (A)\"e2 ef e2 ef | \"A7\" gf ed cB Ac |\\n\"D\"d2 fd \"A\"c2 ec | \"G\"Bc dB \"D\"AF ED | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF \"D\"D2-D2 :|\\n\\n'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiskey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:2\n",
      "B:16\n",
      "M:4/4\n",
      "K:G\n",
      " FABA F2 ED | ABAG FDEF |\"A\" ED CB, A,2 A,A, |\"A\" E2 EF GF EF | \n",
      "\"D\" DD EF A2 AA | \n",
      " AB AG FE DF | \n",
      "\"G\" G2 BG\"D\" F2 AF | \n",
      "\"A\" ED EF\"D\" D4 :: \n",
      " ed ef d3 A | \n",
      "\"G\" B2 Bc BA Bc | \n",
      "\"A\" gf ed cB A2 :| \n",
      "\"D\" d2 dd f2 ff | \n",
      "\"G\" Bc dB\"D\" A2 FA | \n",
      "\"G\" G2 BG\"D\" F2 AF | \n",
      "\"A\" ED EF\"D\" D2 D2 :|\n"
     ]
    }
   ],
   "source": [
    "tortured_whiskey =[]\n",
    "n_seed=None\n",
    "for i in range(whiskey_embedding.shape[1]):\n",
    "    token = None\n",
    "    tokens = torch.tensor([patchilizer.bos_token_id],device=device)\n",
    "    this_patch = whiskey_embedding[0,i]\n",
    "    while token != patchilizer.eos_token_id and len(tokens)< PATCH_SIZE-1:\n",
    "        prob = model.char_level_decoder.generate(this_patch,tokens).cpu().detach().numpy()\n",
    "        prob = top_p_sampling(prob, top_p=top_p, return_probs=True)\n",
    "        prob = top_k_sampling(prob, top_k=top_k, return_probs=True)\n",
    "        token = temperature_sampling(prob, temperature=temperature, seed=n_seed)\n",
    "        tokens = torch.cat([tokens,torch.tensor([token],device=device)],dim=0)\n",
    "    tortured_whiskey.append(tokens)\n",
    "print(patchilizer.decode(tortured_whiskey))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiskey_embedding.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "X:1\n",
      "L:1/8\n",
      "M:4/4\n",
      "K:D\n",
      "|: \"D\"DE FG A2 AA | AB AG FE DF | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF EC B,A, |\n",
      "\"D\"DE FG A2 AA | AB AG FE DF | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF \"D\"D2 A2 ::\n",
      "\"D\"A2 d2 d2 dd | f2 d2 B2 A2 | \"Em (A)\"e2 ef e2 ef | \"A7\" gf ed cB Ac |\n",
      "\"D\"d2 fd \"A\"c2 ec | \"G\"Bc dB \"D\"AF ED | \"G\"G2 BG \"D\"F2 AF | \"A\"ED EF \"D\"D2-D2 :|\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(whiskey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"abcs/st-annes-reel.abc\") as f:\n",
    "    anne = f.read()\n",
    "anne = \"X:1\\nM:4/4\\n\"+anne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "anne_patches = torch.tensor([patchilizer.encode(anne,add_special_patches=True)[:-1]],device=device)\n",
    "anne_embedding = model.patch_level_decoder(anne_patches)[\"last_hidden_state\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:2\n",
      "B:16\n",
      "K:G\n",
      "M:4/4\n",
      "|: A2 FA DAFA |\"D\" A2 F2 F2 A2 |\"G\" B2 BG D2 D2 |\"D\" A2 FADFAF |\"G\" f2 fgfedB | A2 AFDFAd |1 \n",
      "\"G\" B2 BA\"A\" cABc :| \n",
      "\"D\" d2 d2 d4 :| \n",
      "\"Em\" gfed\"A7\" cdef | \n",
      "\"A7\" gececege | \n",
      "\"D\" fded\"A7\" cAde :| \n",
      "\"D\" fdAd fdfa | \n",
      "\"Em\" aggf g2 ef | \n",
      "\"A7\" gfecAce | \n",
      " fdec\"D\" d4 :|\n"
     ]
    }
   ],
   "source": [
    "tortured_anne =[]\n",
    "n_seed=None\n",
    "for i in range(anne_embedding.shape[1]):\n",
    "    token = None\n",
    "    tokens = torch.tensor([patchilizer.bos_token_id],device=device)\n",
    "    this_patch = anne_embedding[0,i]\n",
    "    while token != patchilizer.eos_token_id and len(tokens)< PATCH_SIZE-1:\n",
    "        prob = model.char_level_decoder.generate(this_patch,tokens).cpu().detach().numpy()\n",
    "        prob = top_p_sampling(prob, top_p=top_p, return_probs=True)\n",
    "        prob = top_k_sampling(prob, top_k=top_k, return_probs=True)\n",
    "        token = temperature_sampling(prob, temperature=temperature, seed=n_seed)\n",
    "        tokens = torch.cat([tokens,torch.tensor([token],device=device)],dim=0)\n",
    "    tortured_anne.append(tokens)\n",
    "print(patchilizer.decode(tortured_anne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
